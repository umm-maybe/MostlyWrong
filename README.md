# MostlyWrong 

## What this is

A set of summaries of blog posts by Eliezer Yudkowsky, generated by [a machine learning algorithm.](https://huggingface.co/facebook/bart-large-cnn)

## Why it exists

EY's blog [LessWrong](https://lesswrong.com) has become a popular forum for people in the "AI Alignment" community.  In fact, there is an [Alignment Forum](https://www.alignmentforum.org/about) site which is "integrated" with LessWrong. You can log in there with your LessWrong username--except you can't post unless you have proven yourself worthy to be invited.

If something about AI alignment discourse doesn't make sense to you, and you want to ask someone on the Alignment Forum for clarification, but haven't been invited, you might think you could get noticed by posting or commenting on LessWrong. But wait! On the front page of LessWrong you may see a notification urging you to read at least 50 of Elezier's blog posts (7 hours of reading) plus "Rationality A-Z", a collection of the blog posts he wrote daily for two years, before participating in the community. 

Haven't got time for that? Me neither! This "Cliff's Notes" version is for you. Skim it (or pretend to), and go pester some longtermists with short-term concerns!

## How I did it

1. Download [the aforementioned blog posts in epub format](https://www.lesswrong.com/posts/ZYtwnKwXmEAWhm8dT/an-epub-of-eliezer-s-blog-posts)
2. Convert them to txt [using Zamzar](https://www.zamzar.com/convert/epub-to-txt/)
3. Create a python virtual environment and run `pip3 install transformers`
4. Code and run the files *summarize_corpus.py* and *lw_csv2md.py*
5. Review and lightly edit (e.g. to remove names that exist in the training corpus but not in the text)

## Where is it
[Here](lesswrong_summaries.md)

